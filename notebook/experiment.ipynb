{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a378212e",
   "metadata": {},
   "source": [
    "### ***--- Imports ---***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32cd8111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict\n",
    "from typing import List\n",
    "from typing import Optional\n",
    "from langchain.schema import Document\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph import END\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.tools.wikipedia.tool import WikipediaQueryRun\n",
    "from langchain_community.utilities.wikipedia import WikipediaAPIWrapper\n",
    "from langchain_community.tools.ddg_search.tool import DuckDuckGoSearchRun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9ab5c7",
   "metadata": {},
   "source": [
    "### ***--- Load environment variables and API keys ---***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e60c2a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9f39a5",
   "metadata": {},
   "source": [
    "### ***--- Load & index medical PDF for RAG ---***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4c87763",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader('../data/medical_book.pdf')\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7530d508",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=128,\n",
    "    separators=[\"\\n\\n\", \". \", \"\\n\", \" \"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8ddcd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bcac50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emon1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4def2e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emon1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"../medical_db/\",\n",
    "    collection_metadata={\"hnsw:space\": \"cosine\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd473c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={'k':3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdea8393",
   "metadata": {},
   "source": [
    "### ***--- Initialize LLM ---***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0acad518",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    model_name=\"openai/gpt-oss-120b\",\n",
    "    temperature=0.3,\n",
    "    max_tokens=2048\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ebee66",
   "metadata": {},
   "source": [
    "### ***--- Initialize external tools ---***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e421c9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = WikipediaAPIWrapper(\n",
    "    api_wrapper=WikipediaAPIWrapper(\n",
    "        top_k_results=2,\n",
    "        doc_content_chars_max=2000,\n",
    "        load_all_available_meta=True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88153e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "duckduckgo_search = DuckDuckGoSearchRun()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bdde66",
   "metadata": {},
   "source": [
    "### ***--- Define AgentState TypedDict with success/failure flags ---***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0ec6e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    question: str\n",
    "    documents: List[Document]\n",
    "    generation: str\n",
    "    source: str\n",
    "    search_query: Optional[str]\n",
    "    conversation_history: List[str]\n",
    "    llm_attempted: bool\n",
    "    llm_success: bool\n",
    "    rag_attempted: bool\n",
    "    rag_success: bool\n",
    "    wiki_attempted: bool\n",
    "    wiki_success: bool\n",
    "    ddg_attempted: bool\n",
    "    ddg_success: bool\n",
    "    current_tool: Optional[str]\n",
    "    retry_count: int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432e55ee",
   "metadata": {},
   "source": [
    "### ***--- Memory Agent (maintain short-term conversation buffer) ---***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e9de11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MemoryAgent(state: AgentState) -> AgentState:\n",
    "    history = state.get(\"conversation_history\", [])\n",
    "    if len(history) > 20:\n",
    "        history = history[-20:]  # keep last 20 messages\n",
    "    state[\"conversation_history\"] = history\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ee8ee7",
   "metadata": {},
   "source": [
    "### ***--- LLM Agent: first attempt to answer ---***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf0c3536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LLMAgent(state: AgentState) -> AgentState:\n",
    "    try:\n",
    "        ctx = \"\\n\".join(state.get(\"conversation_history\", [])[-10:])\n",
    "        prompt = f\"\"\"You are a compassionate and knowledgeable medical AI assistant and doctor helping a patient. Your conversational skill should be a professional consultant with a human touch.\n",
    "\n",
    "Patient's History:\n",
    "{ctx}\n",
    "\n",
    "Patient's Question:\n",
    "{state['question']}\n",
    "\n",
    "Respond like an experienced doctor in 2–3 sentences. Be clear, professional, and confident. Do not mention sources or uncertainty.\"\"\"\n",
    "\n",
    "        response = llm.invoke(prompt)\n",
    "        answer = response.content.strip()\n",
    "\n",
    "        if answer:\n",
    "            state[\"generation\"] = answer\n",
    "            state[\"llm_success\"] = True\n",
    "        else:\n",
    "            state[\"llm_success\"] = False\n",
    "    except Exception:\n",
    "        state[\"llm_success\"] = False\n",
    "\n",
    "    state[\"llm_attempted\"] = True\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a8d16c",
   "metadata": {},
   "source": [
    "### ***--- Planner Agent: initial tool decision based on query keywords ---***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e488d053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlannerAgent(state: AgentState) -> AgentState:\n",
    "    question = state[\"question\"].lower()\n",
    "    medical_keywords = [\"pain\", \"fever\", \"treatment\", \"symptom\", \"diagnosis\", \"cancer\", \"disease\", \"virus\", \"bacteria\", \"infection\"]\n",
    "\n",
    "    if any(word in question for word in medical_keywords):\n",
    "        state[\"current_tool\"] = \"llm\"  # Start with LLM for compassionate answer first\n",
    "    else:\n",
    "        state[\"current_tool\"] = \"llm\"  # Default start with LLM\n",
    "    state[\"retry_count\"] = 0\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc71e7ae",
   "metadata": {},
   "source": [
    "### ***--- Retriever Agent (RAG) from PDF vectorstore ---***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "863ba198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RetrieverAgent(state: AgentState) -> AgentState:\n",
    "    query = state[\"question\"]\n",
    "    context = \"\\n\".join(state.get(\"conversation_history\", [])[-6:])\n",
    "    combined_query = f\"Context: {context}\\nQuestion: {query}\"\n",
    "\n",
    "    try:\n",
    "        docs = retriever.invoke(combined_query)\n",
    "        if docs and len(docs) > 0:\n",
    "            state[\"documents\"] = docs\n",
    "            state[\"rag_success\"] = True\n",
    "            state[\"conversation_history\"].append(\"AI: Retrieved documents from medical PDF database.\")\n",
    "        else:\n",
    "            state[\"documents\"] = []\n",
    "            state[\"rag_success\"] = False\n",
    "    except Exception:\n",
    "        state[\"documents\"] = []\n",
    "        state[\"rag_success\"] = False\n",
    "\n",
    "    state[\"rag_attempted\"] = True\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3a0445",
   "metadata": {},
   "source": [
    "### ***--- Wikipedia Agent fallback ---***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8f38f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def WikipediaAgent(state: AgentState) -> AgentState:\n",
    "    try:\n",
    "        content = wiki.run(state[\"question\"])\n",
    "        if content:\n",
    "            state[\"documents\"] = [Document(page_content=content)]\n",
    "            state[\"wiki_success\"] = True\n",
    "            state[\"conversation_history\"].append(\"AI: Retrieved information from Wikipedia.\")\n",
    "        else:\n",
    "            state[\"documents\"] = []\n",
    "            state[\"wiki_success\"] = False\n",
    "    except Exception:\n",
    "        state[\"documents\"] = []\n",
    "        state[\"wiki_success\"] = False\n",
    "\n",
    "    state[\"wiki_attempted\"] = True\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a551a5fb",
   "metadata": {},
   "source": [
    "### ***--- DuckDuckGo Agent fallback ---***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f672cbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DuckDuckGoAgent(state: AgentState) -> AgentState:\n",
    "    try:\n",
    "        content = duckduckgo_search.run(state[\"question\"])\n",
    "        if content:\n",
    "            state[\"documents\"] = [Document(page_content=content)]\n",
    "            state[\"ddg_success\"] = True\n",
    "            state[\"conversation_history\"].append(\"AI: Retrieved information from DuckDuckGo.\")\n",
    "        else:\n",
    "            state[\"documents\"] = []\n",
    "            state[\"ddg_success\"] = False\n",
    "    except Exception:\n",
    "        state[\"documents\"] = []\n",
    "        state[\"ddg_success\"] = False\n",
    "\n",
    "    state[\"ddg_attempted\"] = True\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc18e721",
   "metadata": {},
   "source": [
    "### ***--- Executor Agent - generate final answer using LLM with retrieved docs or fallback to knowledge ---***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b6f82659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExecutorAgent(state: AgentState) -> AgentState:\n",
    "    context = state.get(\"conversation_history\", [])\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Use docs if available\n",
    "    if state.get(\"documents\") and len(state[\"documents\"]) > 0:\n",
    "        content = \"\\n\".join([doc.page_content for doc in state[\"documents\"]])\n",
    "        prompt = f\"\"\"You are a kind, highly experienced professional medical doctor speaking directly with a patient. Be clear, supportive and concise like human response.\n",
    "\n",
    "Conversation Context:\n",
    "{\"\".join(context[-6:])}\n",
    "\n",
    "Patient's Question:\n",
    "{question}\n",
    "\n",
    "Relevant Medical Information:\n",
    "{content}\n",
    "\n",
    "Guidelines:\n",
    "- Answer in 2-3 sentences.\n",
    "- Do not mention sources.\n",
    "- Speak like a caring human doctor.\"\"\"\n",
    "\n",
    "        response = llm.invoke(prompt)\n",
    "        answer = response.content.strip()\n",
    "        state[\"generation\"] = answer\n",
    "        state[\"source\"] = \"retrieved_docs\"\n",
    "        state[\"conversation_history\"].append(f\"Doctor: {answer}\")\n",
    "        return state\n",
    "\n",
    "    # If no docs but LLM succeeded earlier, use that generation\n",
    "    if state.get(\"llm_success\", False) and state.get(\"generation\"):\n",
    "        state[\"conversation_history\"].append(f\"Doctor: {state['generation']}\")\n",
    "        state[\"source\"] = \"llm_knowledge\"\n",
    "        return state\n",
    "\n",
    "    # Otherwise fallback response\n",
    "    state[\"generation\"] = \"I couldn’t find enough information to answer your question right now. Please consult a licensed medical professional.\"\n",
    "    state[\"source\"] = \"none\"\n",
    "    state[\"conversation_history\"].append(state[\"generation\"])\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30265f9f",
   "metadata": {},
   "source": [
    "### ***--- Explanation Agent (append explanation, confidence, traceability) ---***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d96c255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExplanationAgent(state: AgentState) -> AgentState:\n",
    "    explanation = \"This response is generated using a combination of medical literature and AI reasoning.\"\n",
    "    state[\"conversation_history\"].append(f\"AI Explanation: {explanation}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcad3d6",
   "metadata": {},
   "source": [
    "### ***--- Build LangGraph workflow ---***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a33f57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c47541a",
   "metadata": {},
   "source": [
    "### ***--- Add all agent nodes ---***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "243a0802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1d7186bef10>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_node(\"memory\", MemoryAgent)\n",
    "workflow.add_node(\"planner\", PlannerAgent)\n",
    "workflow.add_node(\"llm_agent\", LLMAgent)\n",
    "workflow.add_node(\"retriever\", RetrieverAgent)\n",
    "workflow.add_node(\"wikipedia\", WikipediaAgent)\n",
    "workflow.add_node(\"duckduckgo\", DuckDuckGoAgent)\n",
    "workflow.add_node(\"executor\", ExecutorAgent)\n",
    "workflow.add_node(\"explanation\", ExplanationAgent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece14096",
   "metadata": {},
   "source": [
    "### ***--- Set entry point ---***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb87e138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1d7186bef10>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.set_entry_point(\"memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0479930",
   "metadata": {},
   "source": [
    "### ***--- Edges and conditional routing functions for fallback chain ---***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d5ce3307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1d7186bef10>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_edge(\"memory\", \"planner\")\n",
    "workflow.add_edge(\"planner\", \"llm_agent\")\n",
    "\n",
    "# After LLM agent\n",
    "def route_after_llm(state: AgentState):\n",
    "    if state.get(\"llm_success\", False):\n",
    "        return \"executor\"\n",
    "    else:\n",
    "        return \"retriever\"\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"llm_agent\",\n",
    "    route_after_llm,\n",
    "    {\n",
    "        \"executor\": \"executor\",\n",
    "        \"retriever\": \"retriever\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# After Retriever agent\n",
    "def route_after_rag(state: AgentState):\n",
    "    if state.get(\"rag_success\", False):\n",
    "        return \"executor\"\n",
    "    else:\n",
    "        return \"wikipedia\"\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"retriever\",\n",
    "    route_after_rag,\n",
    "    {\n",
    "        \"executor\": \"executor\",\n",
    "        \"wikipedia\": \"wikipedia\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# After Wikipedia agent\n",
    "def route_after_wiki(state: AgentState):\n",
    "    if state.get(\"wiki_success\", False):\n",
    "        return \"executor\"\n",
    "    else:\n",
    "        return \"duckduckgo\"\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"wikipedia\",\n",
    "    route_after_wiki,\n",
    "    {\n",
    "        \"executor\": \"executor\",\n",
    "        \"duckduckgo\": \"duckduckgo\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# After DuckDuckGo agent\n",
    "def route_after_ddg(state: AgentState):\n",
    "    # No fallback after ddg, go to executor anyway\n",
    "    return \"executor\"\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"duckduckgo\",\n",
    "    route_after_ddg,\n",
    "    {\n",
    "        \"executor\": \"executor\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Executor to explanation then end\n",
    "workflow.add_edge(\"executor\", \"explanation\")\n",
    "workflow.add_edge(\"explanation\", END)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4957b497",
   "metadata": {},
   "source": [
    "### ***--- Compile the workflow ---***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a8eb512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e827b9",
   "metadata": {},
   "source": [
    "### ***--- Initialize conversation state ---***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d847f7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_state: AgentState = {\n",
    "    \"question\": \"\",\n",
    "    \"documents\": [],\n",
    "    \"generation\": \"\",\n",
    "    \"source\": \"\",\n",
    "    \"search_query\": None,\n",
    "    \"conversation_history\": [],\n",
    "    \"llm_attempted\": False,\n",
    "    \"llm_success\": False,\n",
    "    \"rag_attempted\": False,\n",
    "    \"rag_success\": False,\n",
    "    \"wiki_attempted\": False,\n",
    "    \"wiki_success\": False,\n",
    "    \"ddg_attempted\": False,\n",
    "    \"ddg_success\": False,\n",
    "    \"current_tool\": None,\n",
    "    \"retry_count\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca71e555",
   "metadata": {},
   "source": [
    "### ***--- Main interaction loop ---***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "862db488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Medical AI Assistant (Type 'exit' to quit) ===\n",
      "\n",
      "[Doctor AI] Acne is often caused by excess oil, clogged pores, and bacteria, and it can usually be managed with a consistent skincare routine and, if needed, topical treatments. Start by gently cleansing your face twice daily with a mild, non‑comedogenic cleanser, avoid picking or squeezing lesions, and consider using an over‑the‑counter product containing benzoyl peroxide or salicylic acid. If the breakouts persist, become painful, or spread rapidly, schedule an appointment so we can assess whether prescription therapy or a tailored treatment plan is needed.\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "[Doctor AI] Maintain a gentle, twice‑daily cleansing routine with a mild, non‑comedogenic cleanser, and follow up with a lightweight, oil‑free moisturizer; avoid touching, picking, or squeezing lesions, and limit exposure to heavy cosmetics or oily hair products. Use an over‑the‑counter topical containing benzoyl peroxide or salicylic acid daily, and protect your skin from excessive sun and stress, which can worsen breakouts. If you notice persistent or worsening lesions, schedule an appointment for a personalized treatment plan.\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "=== Consultation Ended. Conversation history cleared. ===\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Medical AI Assistant (Type 'exit' to quit) ===\")\n",
    "\n",
    "while True:\n",
    "    query = input(\"\\nAsk your medical question: \").strip()\n",
    "\n",
    "    if query.lower() == \"exit\":\n",
    "        # Reset conversation history and state on exit\n",
    "        conversation_state = {\n",
    "            \"question\": \"\",\n",
    "            \"documents\": [],\n",
    "            \"generation\": \"\",\n",
    "            \"source\": \"\",\n",
    "            \"search_query\": None,\n",
    "            \"conversation_history\": [],\n",
    "            \"llm_attempted\": False,\n",
    "            \"llm_success\": False,\n",
    "            \"rag_attempted\": False,\n",
    "            \"rag_success\": False,\n",
    "            \"wiki_attempted\": False,\n",
    "            \"wiki_success\": False,\n",
    "            \"ddg_attempted\": False,\n",
    "            \"ddg_success\": False,\n",
    "            \"current_tool\": None,\n",
    "            \"retry_count\": 0\n",
    "        }\n",
    "        print(\"\\n=== Consultation Ended. Conversation history cleared. ===\")\n",
    "        break\n",
    "\n",
    "    # Update conversation state with new question\n",
    "    conversation_state.update({\n",
    "        \"question\": query,\n",
    "        \"documents\": [],\n",
    "        \"generation\": \"\",\n",
    "        \"source\": \"\",\n",
    "        \"search_query\": None,\n",
    "        \"llm_attempted\": False,\n",
    "        \"llm_success\": False,\n",
    "        \"rag_attempted\": False,\n",
    "        \"rag_success\": False,\n",
    "        \"wiki_attempted\": False,\n",
    "        \"wiki_success\": False,\n",
    "        \"ddg_attempted\": False,\n",
    "        \"ddg_success\": False,\n",
    "        \"current_tool\": None,\n",
    "        \"retry_count\": 0\n",
    "    })\n",
    "\n",
    "    # Run the LangGraph workflow with current state\n",
    "    result = app.invoke(conversation_state)\n",
    "    conversation_state.update(result)\n",
    "\n",
    "    # Print AI response\n",
    "    if result.get(\"generation\"):\n",
    "        print(f\"\\n[Doctor AI] {result['generation']}\")\n",
    "    else:\n",
    "        print(\"\\n[Doctor AI] Sorry, I couldn't generate a response.\")\n",
    "\n",
    "    print(\"\\n\" + \"-\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
